{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "2iwoHPmkeRRm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dev_size = 0.8 * x_train.shape[0]\n",
        "dev_size = int(dev_size)\n",
        "\n",
        "\n",
        "x_val = x_train[dev_size:]\n",
        "y_val = y_train[dev_size:]\n",
        "y_val = y_train[dev_size:]\n",
        "\n",
        "#shuffle the x train\n",
        "indices = np.arange(x_train.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "x_train = x_train[indices]\n",
        "y_train = y_train[indices]\n",
        "\n",
        "x_train = x_train[:dev_size]\n",
        "y_train = y_train[:dev_size]\n",
        "\n",
        "#preparing the training data\n",
        "x_train = (x_train/255.0).reshape(-1,28*28)\n",
        "x_val= (x_val/255.0).reshape(-1,28*28)\n",
        "x_test = (x_test/255.0).reshape(-1,28*28)\n",
        "\n",
        "#make the ohe\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_val = tf.keras.utils.to_categorical(y_val)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Print shapes\n",
        "print(x_train.shape)  # (60000, 28, 28)\n",
        "print(y_train.shape)  # (60000,)\n",
        "print(x_test.shape)   # (10000, 28, 28)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlbWNqDyeadp",
        "outputId": "2769c791-4745-4235-b913-4605545e6da7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "(48000, 784)\n",
            "(48000, 10)\n",
            "(10000, 784)\n",
            "(10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model\n",
        "\n",
        "class MLP(tf.keras.Model):\n",
        "  def __init__(self, num_classes, input_shape, n_layers, n_units, activation):\n",
        "    super(MLP, self).__init__()\n",
        "    self.num_classes = num_classes\n",
        "    self.input_shape = input_shape\n",
        "    self.n_layers = n_layers\n",
        "    self.n_units = n_units\n",
        "    self\n",
        "    self.activation = activation\n",
        "\n",
        "    self.model = self.create_model()\n",
        "\n",
        "  def create_model(self):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Input(shape=self.input, activation=self.activation))\n",
        "    for i in range(self.n_layers):\n",
        "      model.add(tf.keras.layers.Dense(self.n_units, activation=self.activation))\n",
        "\n",
        "      model.add (tf.keras.layers.Input(shape=self.input_shape))\n",
        "      model.add(tf.keras.layers.Dense(self.num_classes, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "  def compile_model(self):\n",
        "    self.model.compile(optimizer='self', loss='self.loss', metrics=['accuracy'])\n",
        "  def train_model(self, x_test, y_test):\n",
        "    test_loss, test_accuracy = self.model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "6MX1JAgtkqt8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class MLP(tf.keras.Model):\n",
        "    def __init__(self, num_classes, input_shape, n_layers,\n",
        "                 n_units, activation,\n",
        "                 optim, loss,):\n",
        "        super(MLP, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.input_shape = input_shape\n",
        "        self.n_layers = n_layers\n",
        "        self.n_units = n_units\n",
        "        self.activation = activation\n",
        "        self.optimizer = optim\n",
        "        self.loss =loss\n",
        "\n",
        "        # Create the model\n",
        "        self.model = self.create_model()\n",
        "\n",
        "    def create_model(self):\n",
        "        model = tf.keras.Sequential()\n",
        "\n",
        "        # First layer (input layer)\n",
        "        model.add(tf.keras.layers.Input(shape=self.input_shape))\n",
        "\n",
        "        # Hidden layers\n",
        "        for _ in range(self.n_layers):\n",
        "            model.add(tf.keras.layers.Dense(self.n_units, activation=self.activation))\n",
        "\n",
        "        # Output layer\n",
        "        model.add(tf.keras.layers.Dense(self.num_classes, activation='softmax'))\n",
        "\n",
        "        return model\n",
        "\n",
        "    def compile_model(self):\n",
        "        self.model.compile(optimizer=self.optimizer, loss=self.loss, metrics=['accuracy'])\n",
        "\n",
        "    def train_model(self, x_train, y_train, x_val, y_val, epochs=10, batch_size=32):\n",
        "        self.model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_val, y_val))\n",
        "\n",
        "\n",
        "    def evaluate_model(self, x_test, y_test):\n",
        "        test_loss, test_accuracy = self.model.evaluate(x_test, y_test)\n"
      ],
      "metadata": {
        "id": "-XTb1MKykqrW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp= MLP(num_classes=10,\n",
        "         input_shape=(28*28,),\n",
        "         n_layers=3,\n",
        "         n_units=128,\n",
        "         activation='relu',\n",
        "         optim = tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "         loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "         )"
      ],
      "metadata": {
        "id": "ieno0Is-kqot"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "mlp.compile_model()\n",
        "start = time.time()\n",
        "mlp.train_model(x_train, y_train, x_val, y_val, epochs=10, batch_size=64)\n",
        "end= time.time()\n",
        "print(f\"training time : {end - start }seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufczxr-mkqlo",
        "outputId": "8984a62b-2d88-4c4a-b698-a390a1f6016c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.8476 - loss: 0.5174 - val_accuracy: 0.9592 - val_loss: 0.1253\n",
            "Epoch 2/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9638 - loss: 0.1201 - val_accuracy: 0.9746 - val_loss: 0.0768\n",
            "Epoch 3/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9771 - loss: 0.0762 - val_accuracy: 0.9836 - val_loss: 0.0525\n",
            "Epoch 4/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9820 - loss: 0.0560 - val_accuracy: 0.9779 - val_loss: 0.0699\n",
            "Epoch 5/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9846 - loss: 0.0505 - val_accuracy: 0.9869 - val_loss: 0.0436\n",
            "Epoch 6/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9876 - loss: 0.0376 - val_accuracy: 0.9883 - val_loss: 0.0383\n",
            "Epoch 7/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9907 - loss: 0.0300 - val_accuracy: 0.9881 - val_loss: 0.0418\n",
            "Epoch 8/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9916 - loss: 0.0256 - val_accuracy: 0.9856 - val_loss: 0.0472\n",
            "Epoch 9/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9928 - loss: 0.0224 - val_accuracy: 0.9922 - val_loss: 0.0312\n",
            "Epoch 10/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9923 - loss: 0.0226 - val_accuracy: 0.9923 - val_loss: 0.0288\n",
            "training time : 64.95512557029724seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Assuming mlp is an instance of your MLP model class\n",
        "mlp.compile_model()  # Compile the model\n",
        "\n",
        "# Start the timer\n",
        "start = time.time()\n",
        "\n",
        "# Train the model\n",
        "mlp.train_model(x_train, y_train, x_val, y_val, epochs=10, batch_size=64)\n",
        "\n",
        "# End the timer\n",
        "end = time.time()\n",
        "\n",
        "# Print the training time\n",
        "print(f\"Training time: {end - start} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yc4eP5oWfhk",
        "outputId": "a4abb13f-748e-4c38-91fd-4e5a2a4f1cac"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.9942 - loss: 0.0163 - val_accuracy: 0.9912 - val_loss: 0.0315\n",
            "Epoch 2/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9939 - loss: 0.0181 - val_accuracy: 0.9906 - val_loss: 0.0361\n",
            "Epoch 3/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9950 - loss: 0.0150 - val_accuracy: 0.9885 - val_loss: 0.0441\n",
            "Epoch 4/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9950 - loss: 0.0144 - val_accuracy: 0.9923 - val_loss: 0.0282\n",
            "Epoch 5/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9964 - loss: 0.0104 - val_accuracy: 0.9879 - val_loss: 0.0438\n",
            "Epoch 6/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9952 - loss: 0.0168 - val_accuracy: 0.9942 - val_loss: 0.0285\n",
            "Epoch 7/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9964 - loss: 0.0127 - val_accuracy: 0.9896 - val_loss: 0.0474\n",
            "Epoch 8/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9962 - loss: 0.0133 - val_accuracy: 0.9877 - val_loss: 0.0501\n",
            "Epoch 9/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9968 - loss: 0.0122 - val_accuracy: 0.9908 - val_loss: 0.0386\n",
            "Epoch 10/10\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9964 - loss: 0.0100 - val_accuracy: 0.9932 - val_loss: 0.0302\n",
            "Training time: 74.49551248550415 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp.evaluate_model(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNnwvKRUoIlq",
        "outputId": "9062a8d1-333a-424e-89be-087e1eb6c836"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9774 - loss: 0.1154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "67V5IMkVoOHS",
        "outputId": "f6c9dc63-c976-40d3-d7ff-757139a2de12"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"mlp\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mlp\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential (\u001b[38;5;33mSequential\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │         \u001b[38;5;34m134,794\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">134,794</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m134,794\u001b[0m (526.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,794</span> (526.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m134,794\u001b[0m (526.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,794</span> (526.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iFsNo5TGoOEu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tlLt0mo4oOBF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6ELipVQeumI",
        "outputId": "9c82cc74-fa56-4269-bdaa-36eb22cf77a0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reshape the 1D array (784,) into a 2D array (28, 28)\n",
        "image = x_train[0].reshape(28, 28)\n",
        "\n",
        "# Plot the image\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.axis('off')  # Optional: Hide the axes\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "TfYtn4sSfM0Q",
        "outputId": "6148aff2-aaa1-4fdd-9d0b-f2fc15eb85d7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wpdbp2cEfQQi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}